{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('pydatk')",
   "metadata": {
    "interpreter": {
     "hash": "191f923cb66d773162629997b180780ff6671a6d24890c003180089c1fb45d90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "df.drop(['PassengerId','Name','Ticket','Cabin'],axis=1).to_csv(\"./train_titanic.csv\",index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "df_test.drop(['PassengerId','Name','Ticket','Cabin'],axis=1).to_csv(\"./test_titanic.csv\",index=False)\n",
    "df_test.head()"
   ]
  },
  {
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(''),os.path.pardir)))\n",
    "\n",
    "from datk.model import ModelTrainer\n",
    "\n",
    "# ModelTrainer.create_init_config_file(model_name='RandomForest',target='Survived')\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - Entered kwargs: {'cmd': 'fit', 'data_path': './train_titanic.csv', 'yaml_path': './model_classification.yaml'}\n",
      "INFO - You passed the configurations as a yaml file.\n",
      "INFO - your chosen configuration: {'dataset': {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'Sex'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'}, 'model': {'algorithm': 'RandomForest', 'type': 'classification', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100, 'max_depth': 30}}, 'target': ['Survived']}\n",
      "INFO - dataset_props: {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'Sex'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'} \n",
      "model_props: {'algorithm': 'RandomForest', 'type': 'classification', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100, 'max_depth': 30}} \n",
      " target: ['Survived'] \n",
      "\n",
      "INFO - dataset shape: (891, 8)\n",
      "INFO - dataset attributes: ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
      "INFO - performing a one hot encoding ...\n",
      "INFO - shape of the dataset after encoding => (891, 13)\n",
      "INFO - Check for missing values in the dataset ...  \n",
      "Survived          0\n",
      "Pclass            0\n",
      "Age             177\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Fare              0\n",
      "Sex_female        0\n",
      "Sex_male          0\n",
      "Sex_nan           0\n",
      "Embarked_C        0\n",
      "Embarked_Q        0\n",
      "Embarked_S        0\n",
      "Embarked_nan      0\n",
      "dtype: int64  \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "INFO - shape of the dataset after handling missing values => (891, 13)\n",
      "INFO - y shape: (891, 1) and x shape: (891, 12)\n",
      "INFO - performing a standard scaling ...\n",
      "INFO - Solving a classification problem using ===> RandomForest\n",
      "INFO - model arguments: \n",
      "{'n_estimators': 100, 'max_depth': 30}\n",
      "INFO - executing a RandomForestClassifier algorithm...\n",
      "INFO - performing cross validation ...\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s finished\n",
      "INFO - Folder /Users/rsun/projects/code/pydatoolkit/examples/model_results already exists\n",
      "WARNING - data in the /Users/rsun/projects/code/pydatoolkit/examples/model_results folder will be overridden. If you don't want this, then move the current /Users/rsun/projects/code/pydatoolkit/examples/model_results to another path\n",
      "INFO - Successfully created the directory in /Users/rsun/projects/code/pydatoolkit/examples/model_results \n",
      "INFO - model saved successfully and can be found in the /Users/rsun/projects/code/pydatoolkit/examples/model_results folder\n",
      "INFO - split option detected. The performance will be automatically evaluated using the test data portion\n",
      "INFO - Calculating accuracy_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating f1_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating precision_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating recall_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating roc_auc_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - saving fit description to /Users/rsun/projects/code/pydatoolkit/examples/model_results/description.json\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<datk.model.ModelTrainer at 0x7fc1ca70f6d0>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ModelTrainer(cmd='fit',data_path=\"./train_titanic.csv\",yaml_path=\"./model_classification.yaml\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "eval_params = {\n",
    "    'cmd':'evaluate',\n",
    "    'data_path': './examples/train_titanic.csv'\n",
    "}\n",
    "\n",
    "ModelTrainer(**eval_params)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - Entered kwargs: {'cmd': 'evaluate', 'data_path': './examples/train_titanic.csv'}\n",
      "INFO - path of the pre-fitted model => /Users/rsun/projects/code/pydatoolkit/examples/model_results/model.sav\n",
      "INFO - result path: /Users/rsun/projects/code/pydatoolkit/examples/model_results \n",
      "INFO - loading model form /Users/rsun/projects/code/pydatoolkit/examples/model_results/model.sav \n",
      "ERROR - error occured while preparing the data: (2, 'No such file or directory')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rsun/projects/code/pydatoolkit/datk/model.py\", line 243, in _process_data\n",
      "    dataset = pd.read_csv(self.data_path) if not read_data_options else pd.read_csv(self.data_path,\n",
      "  File \"/Users/rsun/projects/py_venv/pydatk/lib/python3.7/site-packages/pandas/io/parsers.py\", line 688, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/rsun/projects/py_venv/pydatk/lib/python3.7/site-packages/pandas/io/parsers.py\", line 454, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/Users/rsun/projects/py_venv/pydatk/lib/python3.7/site-packages/pandas/io/parsers.py\", line 948, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/Users/rsun/projects/py_venv/pydatk/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1180, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/Users/rsun/projects/py_venv/pydatk/lib/python3.7/site-packages/pandas/io/parsers.py\", line 2010, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './examples/train_titanic.csv'\n",
      "ERROR - error occured during evaluation: cannot unpack non-iterable NoneType object\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rsun/projects/code/pydatoolkit/datk/model.py\", line 470, in evaluate\n",
      "    x_val, y_true = self._prepare_eval_data()\n",
      "TypeError: cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<datk.model.ModelTrainer at 0x7fc1c8c28e50>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "source": [
    "# XGBClassifier Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(''),os.path.pardir)))\n",
    "\n",
    "from datk.model import ModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - Entered kwargs: {'cmd': 'fit', 'data_path': './train_titanic.csv', 'yaml_path': './xgb_model_classification.yaml', 'result_path': './model_results'}\n",
      "INFO - You passed the configurations as a yaml file.\n",
      "INFO - your chosen configuration: {'dataset': {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'Sex'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'}, 'model': {'algorithm': 'XGBClassifier', 'type': 'classification', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100}}, 'target': ['Survived']}\n",
      "INFO - dataset_props: {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'Sex'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'} \n",
      "model_props: {'algorithm': 'XGBClassifier', 'type': 'classification', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100}} \n",
      " target: ['Survived'] \n",
      "\n",
      "INFO - dataset shape: (891, 8)\n",
      "INFO - dataset attributes: ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
      "INFO - performing a one hot encoding ...\n",
      "INFO - shape of the dataset after encoding => (891, 13)\n",
      "INFO - Check for missing values in the dataset ...  \n",
      "Survived          0\n",
      "Pclass            0\n",
      "Age             177\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Fare              0\n",
      "Sex_female        0\n",
      "Sex_male          0\n",
      "Sex_nan           0\n",
      "Embarked_C        0\n",
      "Embarked_Q        0\n",
      "Embarked_S        0\n",
      "Embarked_nan      0\n",
      "dtype: int64  \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "INFO - shape of the dataset after handling missing values => (891, 13)\n",
      "INFO - y shape: (891, 1) and x shape: (891, 12)\n",
      "INFO - performing a standard scaling ...\n",
      "INFO - Solving a classification problem using ===> XGBClassifier\n",
      "INFO - model arguments: \n",
      "{'n_estimators': 100}\n",
      "INFO - executing a XGBClassifier algorithm...\n",
      "INFO - performing cross validation ...\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "INFO - Folder /Users/rsun/projects/code/pydatoolkit/examples/model_results already exists\n",
      "WARNING - data in the /Users/rsun/projects/code/pydatoolkit/examples/model_results folder will be overridden. If you don't want this, then move the current /Users/rsun/projects/code/pydatoolkit/examples/model_results to another path\n",
      "INFO - Successfully created the directory in /Users/rsun/projects/code/pydatoolkit/examples/model_results \n",
      "INFO - model saved successfully and can be found in the /Users/rsun/projects/code/pydatoolkit/examples/model_results folder\n",
      "INFO - split option detected. The performance will be automatically evaluated using the test data portion\n",
      "INFO - Calculating accuracy_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating f1_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating precision_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating recall_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating roc_auc_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - saving fit description to /Users/rsun/projects/code/pydatoolkit/examples/model_results/description.json\n"
     ]
    }
   ],
   "source": [
    "m = ModelTrainer(cmd='fit',data_path=\"./train_titanic.csv\",yaml_path=\"./xgb_model_classification.yaml\",result_path=\"./xgb_classification/model_results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - result path: /Users/rsun/projects/code/pydatoolkit/examples/model_results \n",
      "INFO - loading model form /Users/rsun/projects/code/pydatoolkit/examples/model_results/model.sav \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "m._load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.2418898 , 0.03301828, 0.06490348, 0.02650766, 0.03402461,\n",
       "       0.505119  , 0.        , 0.        , 0.02130944, 0.01348102,\n",
       "       0.05974672, 0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "m.model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "m.model.get_booster().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}