{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('pydatk')",
   "metadata": {
    "interpreter": {
     "hash": "191f923cb66d773162629997b180780ff6671a6d24890c003180089c1fb45d90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "df.drop(['PassengerId','Name','Ticket','Cabin'],axis=1).to_csv(\"./train_titanic.csv\",index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "df_test.drop(['PassengerId','Name','Ticket','Cabin'],axis=1).to_csv(\"./test_titanic.csv\",index=False)\n",
    "df_test.head()"
   ]
  },
  {
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(''),os.path.pardir)))\n",
    "\n",
    "from datk.model import ModelTrainer\n",
    "\n",
    "# ModelTrainer.create_init_config_file(model_name='RandomForest',target='Survived')\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - Entered kwargs: {'cmd': 'fit', 'data_path': './train_titanic.csv', 'yaml_path': './model.yaml'}\n",
      "INFO - You passed the configurations as a yaml file.\n",
      "INFO - your chosen configuration: {'dataset': {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'Sex'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'}, 'model': {'algorithm': 'RandomForest', 'type': 'classification', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100, 'max_depth': 30}}, 'target': ['Survived']}\n",
      "INFO - dataset_props: {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'Sex'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'} \n",
      "model_props: {'algorithm': 'RandomForest', 'type': 'classification', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100, 'max_depth': 30}} \n",
      " target: ['Survived'] \n",
      "\n",
      "INFO - dataset shape: (891, 8)\n",
      "INFO - dataset attributes: ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
      "INFO - performing a one hot encoding ...\n",
      "INFO - shape of the dataset after encoding => (891, 13)\n",
      "INFO - Check for missing values in the dataset ...  \n",
      "Survived          0\n",
      "Pclass            0\n",
      "Age             177\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Fare              0\n",
      "Sex_female        0\n",
      "Sex_male          0\n",
      "Sex_nan           0\n",
      "Embarked_C        0\n",
      "Embarked_Q        0\n",
      "Embarked_S        0\n",
      "Embarked_nan      0\n",
      "dtype: int64  \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "INFO - shape of the dataset after handling missing values => (891, 13)\n",
      "INFO - y shape: (891, 1) and x shape: (891, 12)\n",
      "INFO - performing a standard scaling ...\n",
      "INFO - Solving a classification problem using ===> RandomForest\n",
      "INFO - model arguments: \n",
      "{'n_estimators': 100, 'max_depth': 30}\n",
      "INFO - executing a RandomForestClassifier algorithm...\n",
      "INFO - performing cross validation ...\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s finished\n",
      "INFO - creating model_results folder to save results...\n",
      "path of the results folder: /Users/rsun/projects/code/pydatoolkit/examples/examples/model_results\n",
      "ERROR - Creating the directory /Users/rsun/projects/code/pydatoolkit/examples/examples/model_results failed \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rsun/projects/code/pydatoolkit/datk/model.py\", line 161, in _save_model\n",
      "    os.mkdir(self.results_path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/rsun/projects/code/pydatoolkit/examples/examples/model_results'\n",
      "INFO - split option detected. The performance will be automatically evaluated using the test data portion\n",
      "INFO - Calculating accuracy_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating f1_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating precision_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating recall_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating roc_auc_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - saving fit description to /Users/rsun/projects/code/pydatoolkit/examples/examples/model_results/description.json\n",
      "ERROR - Error while storing the fit description file: [Errno 2] No such file or directory: '/Users/rsun/projects/code/pydatoolkit/examples/examples/model_results/description.json'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rsun/projects/code/pydatoolkit/datk/model.py\", line 433, in fit\n",
      "    with open(self.description_file, 'w', encoding='utf-8') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/rsun/projects/code/pydatoolkit/examples/examples/model_results/description.json'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<datk.model.ModelTrainer at 0x7fdfde6869d0>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "ModelTrainer(cmd='fit',data_path=\"./train_titanic.csv\",yaml_path=\"./model.yaml\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "eval_params = {\n",
    "    'cmd':'evaluate',\n",
    "    'data_path': './examples/train_titanic.csv'\n",
    "}\n",
    "\n",
    "ModelTrainer(**eval_params)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PosixPath('/Users/rsun/projects/code/pydatoolkit/examples/model_results')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "source": [
    "# XGBClassifier Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(''),os.path.pardir)))\n",
    "\n",
    "from datk.model import ModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - Entered kwargs: {'cmd': 'fit', 'data_path': './train_titanic.csv', 'yaml_path': './xgb_model.yaml', 'result_path': './model_results'}\n",
      "INFO - You passed the configurations as a yaml file.\n",
      "INFO - your chosen configuration: {'dataset': {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'Sex'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'}, 'model': {'algorithm': 'XGBClassifier', 'type': 'classification', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100}}, 'target': ['Survived']}\n",
      "INFO - dataset_props: {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'Sex'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'} \n",
      "model_props: {'algorithm': 'XGBClassifier', 'type': 'classification', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100}} \n",
      " target: ['Survived'] \n",
      "\n",
      "INFO - dataset shape: (891, 8)\n",
      "INFO - dataset attributes: ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
      "INFO - performing a one hot encoding ...\n",
      "INFO - shape of the dataset after encoding => (891, 13)\n",
      "INFO - Check for missing values in the dataset ...  \n",
      "Survived          0\n",
      "Pclass            0\n",
      "Age             177\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Fare              0\n",
      "Sex_female        0\n",
      "Sex_male          0\n",
      "Sex_nan           0\n",
      "Embarked_C        0\n",
      "Embarked_Q        0\n",
      "Embarked_S        0\n",
      "Embarked_nan      0\n",
      "dtype: int64  \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "INFO - shape of the dataset after handling missing values => (891, 13)\n",
      "INFO - y shape: (891, 1) and x shape: (891, 12)\n",
      "INFO - performing a standard scaling ...\n",
      "INFO - Solving a classification problem using ===> XGBClassifier\n",
      "INFO - model arguments: \n",
      "{'n_estimators': 100}\n",
      "INFO - executing a XGBClassifier algorithm...\n",
      "INFO - performing cross validation ...\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "INFO - Folder /Users/rsun/projects/code/pydatoolkit/examples/model_results already exists\n",
      "WARNING - data in the /Users/rsun/projects/code/pydatoolkit/examples/model_results folder will be overridden. If you don't want this, then move the current /Users/rsun/projects/code/pydatoolkit/examples/model_results to another path\n",
      "INFO - Successfully created the directory in /Users/rsun/projects/code/pydatoolkit/examples/model_results \n",
      "INFO - model saved successfully and can be found in the /Users/rsun/projects/code/pydatoolkit/examples/model_results folder\n",
      "INFO - split option detected. The performance will be automatically evaluated using the test data portion\n",
      "INFO - Calculating accuracy_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating f1_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating precision_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating recall_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - Calculating roc_auc_score .....\n",
      "INFO - type of target: binary\n",
      "INFO - saving fit description to /Users/rsun/projects/code/pydatoolkit/examples/model_results/description.json\n"
     ]
    }
   ],
   "source": [
    "m = ModelTrainer(cmd='fit',data_path=\"./train_titanic.csv\",yaml_path=\"./xgb_model.yaml\",result_path=\"./model_results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - result path: /Users/rsun/projects/code/pydatoolkit/examples/model_results \n",
      "INFO - loading model form /Users/rsun/projects/code/pydatoolkit/examples/model_results/model.sav \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "m._load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.16558272, 0.03144141, 0.05199086, 0.03429371, 0.03393079,\n",
       "       0.5653124 , 0.        , 0.        , 0.02438377, 0.00956114,\n",
       "       0.08350316, 0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "m.model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "m.model.get_booster().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}