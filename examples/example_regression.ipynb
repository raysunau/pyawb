{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('pydatk')",
   "metadata": {
    "interpreter": {
     "hash": "191f923cb66d773162629997b180780ff6671a6d24890c003180089c1fb45d90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./housing.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create test dataset"
   ]
  },
  {
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(''),os.path.pardir)))\n",
    "\n",
    "from datk.model import ModelTrainer\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - Entered kwargs: {'cmd': 'fit', 'data_path': './housing.csv', 'yaml_path': './model_regression.yaml'}\n",
      "INFO - You passed the configurations as a yaml file.\n",
      "INFO - your chosen configuration: {'dataset': {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'ocean_proximity'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'}, 'model': {'algorithm': 'RandomForest', 'type': 'regression', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100, 'max_depth': 30}}, 'target': ['median_house_value']}\n",
      "INFO - dataset_props: {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'ocean_proximity'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'} \n",
      "model_props: {'algorithm': 'RandomForest', 'type': 'regression', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100, 'max_depth': 30}} \n",
      " target: ['median_house_value'] \n",
      "\n",
      "INFO - dataset shape: (20640, 10)\n",
      "INFO - dataset attributes: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'ocean_proximity']\n",
      "INFO - performing a one hot encoding ...\n",
      "INFO - shape of the dataset after encoding => (20640, 15)\n",
      "INFO - Check for missing values in the dataset ...  \n",
      "longitude                       0\n",
      "latitude                        0\n",
      "housing_median_age              0\n",
      "total_rooms                     0\n",
      "total_bedrooms                207\n",
      "population                      0\n",
      "households                      0\n",
      "median_income                   0\n",
      "median_house_value              0\n",
      "ocean_proximity_<1H OCEAN       0\n",
      "ocean_proximity_INLAND          0\n",
      "ocean_proximity_ISLAND          0\n",
      "ocean_proximity_NEAR BAY        0\n",
      "ocean_proximity_NEAR OCEAN      0\n",
      "ocean_proximity_nan             0\n",
      "dtype: int64  \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "INFO - shape of the dataset after handling missing values => (20640, 15)\n",
      "INFO - y shape: (20640, 1) and x shape: (20640, 14)\n",
      "INFO - performing a standard scaling ...\n",
      "INFO - Solving a regression problem using ===> RandomForest\n",
      "INFO - model arguments: \n",
      "{'n_estimators': 100, 'max_depth': 30}\n",
      "INFO - executing a RandomForestRegressor algorithm...\n",
      "INFO - performing cross validation ...\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   16.4s finished\n",
      "INFO - Folder /Users/rsun/projects/code/pydatoolkit/examples/model_results already exists\n",
      "WARNING - data in the /Users/rsun/projects/code/pydatoolkit/examples/model_results folder will be overridden. If you don't want this, then move the current /Users/rsun/projects/code/pydatoolkit/examples/model_results to another path\n",
      "INFO - Successfully created the directory in /Users/rsun/projects/code/pydatoolkit/examples/model_results \n",
      "INFO - model saved successfully and can be found in the /Users/rsun/projects/code/pydatoolkit/examples/model_results folder\n",
      "INFO - split option detected. The performance will be automatically evaluated using the test data portion\n",
      "INFO - Calculating mean_squared_error .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - Calculating mean_absolute_error .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - Calculating mean_squared_log_error .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - Calculating median_absolute_error .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - Calculating r2_score .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - saving fit description to /Users/rsun/projects/code/pydatoolkit/examples/model_results/description.json\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<datk.model.ModelTrainer at 0x7fb724a2d450>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "ModelTrainer(cmd='fit',data_path=\"./housing.csv\",yaml_path=\"./model_regression.yaml\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "eval_params = {\n",
    "    'cmd':'evaluate',\n",
    "    'data_path': './examples/train_titanic.csv'\n",
    "}\n",
    "\n",
    "ModelTrainer(**eval_params)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PosixPath('/Users/rsun/projects/code/pydatoolkit/examples/model_results')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "source": [
    "# XGBClassifier Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(''),os.path.pardir)))\n",
    "\n",
    "from datk.model import ModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - Entered kwargs: {'cmd': 'fit', 'data_path': './housing.csv', 'yaml_path': './xgb_model_regression.yaml', 'results_path': './xgb_regression/model_results'}\n",
      "INFO - You passed the configurations as a yaml file.\n",
      "INFO - your chosen configuration: {'dataset': {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'ocean_proximity'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'}, 'model': {'algorithm': 'XGBRegressor', 'type': 'regression', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100}}, 'target': ['median_house_value']}\n",
      "INFO - dataset_props: {'preprocess': {'encoding': {'type': 'oneHotEncoding', 'column': 'ocean_proximity'}, 'missing_values': 'mean', 'scale': {'method': 'standard', 'target': 'inputs'}}, 'split': {'shuffle': True, 'test_size': 0.2, 'stratify': 'default'}, 'type': 'csv'} \n",
      "model_props: {'algorithm': 'XGBRegressor', 'type': 'regression', 'cross_validate': {'cv': 3, 'verbose': 1}, 'arguments': {'n_estimators': 100}} \n",
      " target: ['median_house_value'] \n",
      "\n",
      "INFO - dataset shape: (20640, 10)\n",
      "INFO - dataset attributes: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'ocean_proximity']\n",
      "INFO - performing a one hot encoding ...\n",
      "INFO - shape of the dataset after encoding => (20640, 15)\n",
      "INFO - Check for missing values in the dataset ...  \n",
      "longitude                       0\n",
      "latitude                        0\n",
      "housing_median_age              0\n",
      "total_rooms                     0\n",
      "total_bedrooms                207\n",
      "population                      0\n",
      "households                      0\n",
      "median_income                   0\n",
      "median_house_value              0\n",
      "ocean_proximity_<1H OCEAN       0\n",
      "ocean_proximity_INLAND          0\n",
      "ocean_proximity_ISLAND          0\n",
      "ocean_proximity_NEAR BAY        0\n",
      "ocean_proximity_NEAR OCEAN      0\n",
      "ocean_proximity_nan             0\n",
      "dtype: int64  \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "INFO - shape of the dataset after handling missing values => (20640, 15)\n",
      "INFO - y shape: (20640, 1) and x shape: (20640, 14)\n",
      "INFO - performing a standard scaling ...\n",
      "INFO - Solving a regression problem using ===> XGBRegressor\n",
      "INFO - model arguments: \n",
      "{'n_estimators': 100}\n",
      "INFO - executing a XGBRegressor algorithm...\n",
      "INFO - performing cross validation ...\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.4s finished\n",
      "INFO - creating model_results folder to save results...\n",
      "path of the results folder: ./xgb_regression/model_results\n",
      "INFO - Successfully created the directory in ./xgb_regression/model_results \n",
      "INFO - model saved successfully and can be found in the ./xgb_regression/model_results folder\n",
      "INFO - split option detected. The performance will be automatically evaluated using the test data portion\n",
      "INFO - Calculating mean_squared_error .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - Calculating mean_absolute_error .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - Calculating mean_squared_log_error .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - Calculating median_absolute_error .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - Calculating r2_score .....\n",
      "INFO - type of target: multiclass\n",
      "INFO - saving fit description to ./xgb_regression/model_results/description.json\n"
     ]
    }
   ],
   "source": [
    "m = ModelTrainer(cmd='fit',data_path=\"./housing.csv\",yaml_path=\"./xgb_model_regression.yaml\",results_path=\"./xgb_regression/model_results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO - result path: /Users/rsun/projects/code/pydatoolkit/examples/model_results \n",
      "INFO - loading model form /Users/rsun/projects/code/pydatoolkit/examples/model_results/model.sav \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "m._load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.16558272, 0.03144141, 0.05199086, 0.03429371, 0.03393079,\n",
       "       0.5653124 , 0.        , 0.        , 0.02438377, 0.00956114,\n",
       "       0.08350316, 0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "m.model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "m.model.get_booster().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}